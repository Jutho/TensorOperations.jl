<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>TensorOperations.jl · TensorOperations.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>TensorOperations.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><span class="toctext">Home</span><ul><li class="current"><a class="toctext" href>TensorOperations.jl</a><ul class="internal"><li><a class="toctext" href="#Table-of-contents-1">Table of contents</a></li><li><a class="toctext" href="#Installation-1">Installation</a></li><li><a class="toctext" href="#Package-features-1">Package features</a></li><li><a class="toctext" href="#Tensor-operations-1">Tensor operations</a></li><li><a class="toctext" href="#To-do-list-1">To do list</a></li></ul></li><li><a class="toctext" href="indexnotation/">Index notation with macros</a></li><li><a class="toctext" href="functions/">Functions</a></li><li><a class="toctext" href="cache/">Cache for temporaries</a></li><li><a class="toctext" href="implementation/">Implementation</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Home</li><li><a href>TensorOperations.jl</a></li></ul><a class="edit-page" href="https://github.com/Jutho/TensorOperations.jl/blob/master/docs/src/index.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>TensorOperations.jl</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="TensorOperations.jl-1" href="#TensorOperations.jl-1">TensorOperations.jl</a></h1><p><em>Fast tensor operations using a convenient Einstein index notation.</em></p><h2><a class="nav-anchor" id="Table-of-contents-1" href="#Table-of-contents-1">Table of contents</a></h2><ul><li><a href="#TensorOperations.jl-1">TensorOperations.jl</a></li><ul><li><a href="#Table-of-contents-1">Table of contents</a></li><li><a href="#Installation-1">Installation</a></li><li><a href="#Package-features-1">Package features</a></li><li><a href="#Tensor-operations-1">Tensor operations</a></li><li><a href="#To-do-list-1">To do list</a></li></ul><li><a href="indexnotation/#Index-notation-with-macros-1">Index notation with macros</a></li><ul><li><a href="indexnotation/#The-@tensor-macro-1">The <code>@tensor</code> macro</a></li><li><a href="indexnotation/#Contraction-order-and-@tensoropt-macro-1">Contraction order and <code>@tensoropt</code> macro</a></li><li><a href="indexnotation/#Dynamical-tensor-network-contractions-with-ncon-and-@ncon-1">Dynamical tensor network contractions with <code>ncon</code> and <code>@ncon</code></a></li><li><a href="indexnotation/#Multithreading-and-GPU-evaluation-of-tensor-contractions-with-@cutensor-1">Multithreading and GPU evaluation of tensor contractions with <code>@cutensor</code></a></li></ul><li><a href="functions/#Functions-1">Functions</a></li><li><a href="cache/#Cache-for-temporaries-1">Cache for temporaries</a></li><ul><li><a href="cache/#Enabling-and-disabling-the-cache-1">Enabling and disabling the cache</a></li><li><a href="cache/#Cache-and-multithreading-1">Cache and multithreading</a></li></ul><li><a href="implementation/#Implementation-1">Implementation</a></li><ul><li><a href="implementation/#Index-notation-and-the-@tensor-macro-1">Index notation and the <code>@tensor</code> macro</a></li><ul><li><a href="implementation/#Tensors,-a.k.a-indexed-objects-1">Tensors, a.k.a indexed objects</a></li><li><a href="implementation/#The-macros-@tensor-and-@tensoropt-1">The macros <code>@tensor</code> and <code>@tensoropt</code></a></li><li><a href="implementation/#Analyzing-contraction-graphs-(a.k.a-tensor-networks)-and-optimizing-contraction-order-1">Analyzing contraction graphs (a.k.a tensor networks) and optimizing contraction order</a></li></ul><li><a href="implementation/#Building-blocks-1">Building blocks</a></li></ul></ul><h2><a class="nav-anchor" id="Installation-1" href="#Installation-1">Installation</a></h2><p>Install with the package manager, <code>pkg&gt; add TensorOperations</code>.</p><h2><a class="nav-anchor" id="Package-features-1" href="#Package-features-1">Package features</a></h2><ul><li>A macro <code>@tensor</code> for conveniently specifying tensor contractions and index permutations   via Einstein&#39;s index notation convention. The index notation is analyzed at compile time.</li><li>Ability to   <a href="https://doi.org/10.1103/PhysRevE.90.033315">optimize pairwise contraction order</a>   using the <code>@tensoropt</code> macro. This optimization is performed at compile time, and the resulting contraction order is hard coded into the resulting expression. The similar macro <code>@tensoropt_verbose</code> provides more information on the optimization process.</li><li>***New***: a function <code>ncon</code> (for network contractor) for contracting a group of   tensors (a.k.a. a tensor network), as well as a corresponding <code>@ncon</code> macro that   simplifies and optimizes this slightly. Unlike the previous macros, <code>ncon</code> and <code>@ncon</code>   do not analyze the contractions at compile time, thus allowing them to deal with   dynamic networks or index specifications.</li><li>Support for any Julia Base array which qualifies as strided, i.e. such that its entries   are layed out according to a regular pattern in memory. The only exception are   <code>ReinterpretedArray</code> objects (implementation provided by Strided.jl, see below).   Additionally, <code>Diagonal</code> objects whose underlying diagonal data is stored as a strided   vector are supported. This facilitates tensor contractions where one of the operands is   e.g. a diagonal matrix of singular values or eigenvalues, which are returned as a   <code>Vector</code> by Julia&#39;s <code>eigen</code> or <code>svd</code> method.</li><li>***New***: Support for <code>CuArray</code> objects if used together with CuArrays.jl, by relying   on (and thus providing a high level interface into) NVidia&#39;s CUTENSOR library.</li><li>Implementation can easily be extended to other types, by overloading a small set of   methods.</li><li>Efficient implementation of a number of basic tensor operations (see below), by relying   on <a href="https://github.com/Jutho/Strided.jl">Strided.jl</a> and <code>gemm</code> from BLAS for   contractions. The latter is optional but on by default, it can be controlled by a   package wide setting via <code>enable_blas()</code> and <code>disable_blas()</code>. If BLAS is disabled or   cannot be applied (e.g. non-matching or non-standard numerical types), Strided.jl is   also used for the contraction.</li><li>A package wide cache for storing temporary arrays that are generated when evaluating   complex tensor expressions within the <code>@tensor</code> macro (based on the implementation of   <a href="https://github.com/JuliaCollections/LRUCache.jl">LRUCache</a>). By default, the cache is   allowed to use up to 50% of the total machine&#39;s memory.</li></ul><h2><a class="nav-anchor" id="Tensor-operations-1" href="#Tensor-operations-1">Tensor operations</a></h2><p>TensorOperations.jl is centered around 3 basic tensor operations, i.e. primitives in which every more complicated tensor expression is deconstructed.</p><ol><li><p><strong>addition:</strong> Add a (possibly scaled version of) one array to another array, where the  indices of the both arrays might appear in different orders. This operation combines  normal array addition and index permutation. It includes as a special case copying one  array into another with permuted indices.</p><p>The actual implementation is provided by <a href="https://github.com/Jutho/  Strided.jl">Strided.jl</a>, which contains multithreaded implementations and cache-friendly blocking  strategies for an optimal efficiency.</p></li><li><p><strong>trace or inner contraction:</strong> Perform a trace/contraction over pairs of indices of an  array, where the result is a lower-dimensional array. As before, the actual  implementation is provided by <a href="https://github.com/Jutho/Strided.jl">Strided.jl</a>.</p></li><li><p><strong>contraction:</strong> Performs a general contraction of two tensors, where some indices of  one array are paired with corresponding indices in a second array. This is typically  handled by first permuting (a.k.a. transposing) and reshaping the two input arrays such  that the contraction becomes equivalent to a matrix multiplication, which is then  performed by the highly efficient <code>gemm</code> method from BLAS. The resulting array might  need another reshape and index permutation to bring it in its final form.  Alternatively, a native Julia implementation that does not require the additional  transpositions (yet is typically slower) can be selected by using <code>disable_blas()</code>.</p></li></ol><h2><a class="nav-anchor" id="To-do-list-1" href="#To-do-list-1">To do list</a></h2><ul><li>Make it easier to check contraction order and to splice in runtime information, or   optimize based on memory footprint or other custom cost functions.</li></ul><footer><hr/><a class="next" href="indexnotation/"><span class="direction">Next</span><span class="title">Index notation with macros</span></a></footer></article></body></html>
